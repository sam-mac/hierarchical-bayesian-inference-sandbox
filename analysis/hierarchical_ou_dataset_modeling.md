# Hierarchical OU Synthetic Dataset

This document summarises the structure, generation process, and modelling affordances of
the synthetic organisational unit (OU) panel generated by
`src/bayes_tools/helpers/synthetic_data_helpers.py`. The helper simulates nested
operational metrics and intermittent survey waves to mimic business productivity and
engagement data with hierarchical dependence.

## Data generation recap

### Hierarchical structure

The generator builds a three-level hierarchy of regions, sites, and operational units. Each
level contributes multiplicative effects on a latent log productivity scale:

* **Region effects** (`region_eff`) follow a Normal distribution with standard deviation 0.10.
* **Site effects** (`site_eff`) are Normal with standard deviation 0.08 and nested inside
  regions.
* **OU-specific effects** (`ou_eff`) are Normal with standard deviation 0.07, plus an OU level
  drift term (`drift`) that drives gradual monotonic change.

A single call produces a balanced panel with `n_regions × n_sites_per_region × n_ous_per_site`
OUs. Months span `n_years × 12` starting in January 2020, stored as month-start timestamps.

### Time-series dynamics

* **Productivity**: Generated on the log scale as the sum of baseline, hierarchical effects,
  OU drift, shared sinusoidal seasonality (`0.12 * sin(2π m/12)`), and idiosyncratic noise
  with σ = 0.05. The final productivity is exponentiated, ensuring positive support and
  generating log-normal variability.
* **FTE operational headcount**: Drawn from a Normal distribution centred at
  `40 + 0.15 * productivity` with σ = 6, truncated below at five heads to avoid zeros.
  This induces cross-sectional correlation between productivity and capacity.
* **Survey score**: Collected only during `wave_months` (default June and December). Each OU
  has a probability (`wave_missing_prob`) of skipping a wave, introducing item non-response.
  Scores track productivity, scaled to approximately 55±10 with additional Normal noise
  (σ = 2.5).
* **Number of respondents**: Sampled as a Normal draw centred at `0.25 * fte` (σ = 6),
  truncated between 10 and 120 and rounded to integers. Respondent counts are missing when
  the survey is missing.

### Missingness and aggregation

The helper injects missing surveys through two mechanisms: off-wave months never collect
survey data, and wave months may drop out per OU. Productivity and FTE remain complete.

The companion `aggregate_to_parent` function produces site- or region-level monthly panels by
summing productivity, FTE, and respondent counts, while computing respondent-weighted survey
means where available. This enables modelling at multiple hierarchical resolutions.

## Data shaping considerations

1. **Wide vs. long panel layouts**: The default output is a tidy panel with columns
   `(region_id, site_id, ou_code, date, productivity, fte_operational, survey_score,
   n_respondents)`. Analysts can pivot to a multi-index or xarray structure for vectorised
   time-series operations. For joint modelling with wave-only survey data, consider splitting
   the outcome into monthly productivity and semi-annual survey subsets.
2. **Log-transformations**: Productivity’s log-normal construction supports log-transforming
   productivity and FTE to stabilise variance before linear modelling. Survey scores are on an
   approximately Gaussian scale already.
3. **Missing survey handling**: Imputation or missingness modelling is required. Missing not
   at random (MNAR) concerns can be addressed by modelling the wave attendance probability as
   a Bernoulli outcome with predictors such as productivity or FTE.
4. **Aggregation paths**: Depending on the inferential goal, aggregate to site or region via
   the helper to fit models on coarser panels, or construct custom weights (e.g., FTE-weighted
   productivity) before modelling.
5. **Feature engineering**: Seasonality index (`sin`/`cos` pairs), time since baseline, and
   lagged productivity can enrich state-space or regression models. Interaction terms between
   hierarchy levels (e.g., region × wave month) capture structured heterogeneity.

## Modelling approaches

The dataset supports a range of models, each leveraging the hierarchical panel structure and
mixed-frequency outcomes.

### Hierarchical Bayesian and mixed-effects models

* **Linear mixed models (LMMs)** or **hierarchical Bayesian regressions** can model
  productivity or log productivity with random intercepts/slopes at region, site, and OU
  levels. Drift terms can be captured with random slopes on time, while seasonality enters as
  fixed effects. Survey scores at wave months can be modelled jointly with productivity via a
  multivariate hierarchical model, sharing random effects.

### Panel regression frameworks

* **Two-way fixed effects** models treat regions or sites as fixed factors and include time
  dummies for waves, handling unobserved heterogeneity when the number of groups is small.
* **Dynamic panel models** (e.g., Arellano-Bond GMM) can use lagged productivity to capture
  inertia while instrumenting for endogeneity introduced by the autoregressive structure.

### Gaussian processes (GPs)

* A **spatiotemporal GP** with separable kernels can model productivity trajectories, using
  OU identifiers as categorical inputs via coregionalisation or embedding-based kernels.
  Seasonality is handled through periodic kernels. Sparse GP approximations are recommended if
  the panel is large.
* For survey scores, a GP conditioned on wave observations can interpolate missing waves or
  share structure with productivity via multi-output GP priors.

### State-space models (SSMs)

* **Local linear trend** or **structural time-series** models per OU capture drift and
  seasonality through latent components. Hierarchical sharing of component variances across
  OUs induces borrowing of strength.
* **Dynamic factor models** can treat regions as latent factors influencing site/OUs, linking
  productivity and survey measurements through shared latent states.

### Difference-in-differences and ANCOVA designs

Although the synthetic generator lacks explicit interventions, analysts can simulate
quasi-experiments by designating subsets of OUs as treated at specified months:

* **Difference-in-differences (DiD)** compares treated and control units before and after the
  intervention date, leveraging balanced monthly productivity observations. Hierarchical DiD
  extends the model with random slopes by site or region.
* **ANCOVA** frameworks combine DiD with baseline adjustment: regress post-treatment outcomes
  on treatment indicators and pre-treatment productivity/survey baselines. Repeated measures
  ANCOVA benefits from modelling respondent-weighted survey outcomes to control for varying
  sample sizes.

### Additional strategies

* **Bayesian multilevel ANCOVA** integrates treatment indicators, baseline covariates, and
  hierarchical random effects, enabling partial pooling of treatment impacts across regions or
  sites.
* **Panel regression with heterogeneous treatment effects** employs interaction terms between
  treatment status and region/site identifiers or fits random coefficients models.
* **Joint productivity–survey models**: treat survey scores as noisy measurements of latent
  satisfaction processes influenced by productivity via a regression or shared latent factor.

## Workflow suggestions

1. **Preprocessing**: Convert dates to ordinal indexes, log-transform productivity, and create
   seasonal indicators. Handle missing surveys via imputation or explicit modelling of the
   observation process.
2. **Exploratory analysis**: Use the `visualisation_helpers` to plot trajectories by OU/site
   and inspect the distribution of survey wave attendance.
3. **Model fitting**: Start with simpler mixed-effects or fixed-effect panel models before
   escalating to GP or SSM formulations. Evaluate predictive accuracy and interpretability in
   the context of hierarchical structure and missingness patterns.
4. **Post-processing**: Aggregate posterior draws or fitted values back to site/region levels
   for stakeholder reporting, ensuring respondent-weighted survey summaries remain consistent
   with the helper’s aggregation logic.

This synthetic dataset offers a controlled environment to prototype hierarchical, panel, and
state-space models while accounting for missing-at-random survey waves and correlated
operational metrics.
