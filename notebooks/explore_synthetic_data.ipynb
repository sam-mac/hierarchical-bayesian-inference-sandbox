{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14373f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.13\n",
    "# If needed in a fresh env:\n",
    "#   pip install \"pymc>=5.21\" \"arviz>=0.17\" \"numpy>=2\" \"pandas>=2.2\"\n",
    "from pytensor.tensor.variable import TensorVariable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "\n",
    "# ---- 1) Get synthetic data from your helpers ----\n",
    "from bayes_tools.helpers.synthetic_data_helpers import (\n",
    "    make_hierarchical_ou_dataset,\n",
    "    aggregate_to_parent,\n",
    ")\n",
    "\n",
    "# Build OU-level monthly panel\n",
    "df_ou = make_hierarchical_ou_dataset(\n",
    "    n_regions=1,\n",
    "    n_sites_per_region=3,\n",
    "    n_ous_per_site=4,\n",
    "    n_years=1,\n",
    "    wave_months=(6, 12),\n",
    "    wave_missing_prob=0.,\n",
    "    seed=7,\n",
    ")\n",
    "\n",
    "# (Optional) aggregate to parent level (e.g., 'site' or 'region')\n",
    "# df_site = aggregate_to_parent(df_ou, level=\"site\")\n",
    "\n",
    "# We'll model at the OU level:\n",
    "df = df_ou.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c04a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b60e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"survey_score\"].notna()].groupby([\"ou_code\", \"date\"])[[\"survey_score\", \"productivity\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"survey_score\"].notna()].groupby([\"ou_code\", \"date\"])[[\"survey_score\", \"productivity\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c729090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- 2) Basic feature prep ----\n",
    "# indices\n",
    "df = df_ou.copy()\n",
    "df = df.sort_values([\"ou_code\", \"date\"]).reset_index(drop=True)\n",
    "ou_codes = df[\"ou_code\"].astype(\"category\")\n",
    "ou_idx = ou_codes.cat.codes.to_numpy().astype(\"int32\")\n",
    "\n",
    "# time index (month panel)\n",
    "dates = pd.to_datetime(df[\"date\"])\n",
    "unique_months = np.sort(dates.unique())\n",
    "month_to_idx = {m: i for i, m in enumerate(unique_months)}\n",
    "time_idx = np.array([month_to_idx[d] for d in dates], dtype=\"int32\")\n",
    "T = len(unique_months)\n",
    "G = ou_codes.cat.categories.size\n",
    "\n",
    "# outcomes and predictors\n",
    "y_raw = df[\"productivity\"].to_numpy().astype(\"float64\")\n",
    "# log-transform to make noise closer to Gaussian / stabilize variance\n",
    "y = np.log(y_raw).astype(\"float64\")\n",
    "\n",
    "x_obs = df[\"survey_score\"].to_numpy().astype(\"float64\")  # may contain NaN\n",
    "n_resp = df[\"n_respondents\"].to_numpy()                  # NaN where no survey\n",
    "n_resp_filled = np.where(np.isnan(n_resp), 0.0, n_resp).astype(\"float64\")\n",
    "has_survey = ~np.isnan(x_obs)\n",
    "idx_obs = np.flatnonzero(has_survey)\n",
    "\n",
    "# standardization helpers (kept simple; you can swap for robust scaling)\n",
    "def zscore(a: np.ndarray):\n",
    "    m = np.nanmean(a)\n",
    "    s = np.nanstd(a)\n",
    "    s = s if s > 0 else 1.0\n",
    "    return (a - m) / s, m, s\n",
    "\n",
    "y_z, y_mean, y_sd = zscore(y)      # target\n",
    "x_z = x_obs.copy()\n",
    "if np.isfinite(x_obs[idx_obs]).any():\n",
    "    x_z, x_mean, x_sd = zscore(x_obs)\n",
    "else:\n",
    "    # fallback if synthetic happens to miss every survey (unlikely)\n",
    "    x_mean, x_sd = 0.0, 1.0\n",
    "    x_z = (x_obs - x_mean) / x_sd\n",
    "\n",
    "# ---- 3) PyMC model ----\n",
    "with pm.Model() as model:\n",
    "    # --- Global means for OU intercept/slope (on log-productivity scale) ---\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0.0, 1.0)\n",
    "    mu_beta  = pm.Normal(\"mu_beta\",  0.0, 0.5)\n",
    "\n",
    "    # --- Correlated OU effects: [alpha, beta] via LKJ-Cholesky for robustness ---\n",
    "    L_ou, corr_ab, sds_ab = pm.LKJCholeskyCov(\n",
    "        \"L_ou\",\n",
    "        n=2,\n",
    "        eta=2.0,\n",
    "        sd_dist=pm.HalfNormal.dist(1.0),\n",
    "        compute_corr=True,\n",
    "        store_in_trace=True,\n",
    "    ) # type: ignore\n",
    "    L_ou: TensorVariable = L_ou\n",
    "    assert isinstance(L_ou, TensorVariable) and isinstance(corr_ab, TensorVariable) and isinstance(sds_ab, TensorVariable)\n",
    "    z = pm.Normal(\"z\", 0.0, 1.0, size=(G, 2))          # Gx2\n",
    "    ab = pt.dot(z, L_ou.T)                              # Gx2\n",
    "    alpha_ou = pm.Deterministic(\"alpha_ou\", mu_alpha + ab[:, 0])\n",
    "    beta_ou  = pm.Deterministic(\"beta_ou\",  mu_beta  + ab[:, 1])\n",
    "\n",
    "    # --- Time fixed effects (centered) for the outcome ---\n",
    "    time_raw = pm.Normal(\"time_raw\", 0.0, 1.0, shape=T)\n",
    "    time_eff = time_raw - pt.mean(time_raw)\n",
    "\n",
    "    # --- Latent survey process x* (z-scored scale) ---\n",
    "    # OU-level mean for x*\n",
    "    mu_x = pm.Normal(\"mu_x\", 0.0, 1.0)\n",
    "    sigma_mu_x = pm.HalfNormal(\"sigma_mu_x\", 1.0)\n",
    "    mu_x_ou = pm.Normal(\"mu_x_ou\", mu_x, sigma_mu_x, shape=G)\n",
    "\n",
    "    # Time effect for x* (optional; helps interpolate sparse waves)\n",
    "    time_x_raw = pm.Normal(\"time_x_raw\", 0.0, 1.0, shape=T)\n",
    "    time_x_eff = time_x_raw - pt.mean(time_x_raw)\n",
    "\n",
    "    # Latent x* per OU-month with residual variance\n",
    "    sigma_x = pm.HalfNormal(\"sigma_x\", 1.0)\n",
    "    \n",
    "    # gamma_time_x = pm.Normal(\"gamma_time_x\", 0.0, 0.3)\n",
    "\n",
    "    x_latent = pm.Normal(\n",
    "        \"x_latent\",\n",
    "        # mu_x_ou[ou_idx] + gamma_time_x * time_x_eff[time_idx],  # small/shrunk time wiggle\n",
    "        mu_x_ou[ou_idx] + 0.2 * time_x_eff[time_idx],\n",
    "        sigma_x,\n",
    "        shape=y_z.shape[0],\n",
    "    )\n",
    "\n",
    "    # --- Measurement model where survey is observed ---\n",
    "    # Downweight by sqrt(n_resp): larger n -> lower noise\n",
    "    # Guard against n=0: clamp minimum effective n to 1.\n",
    "    n_eff = pt.clip(pt.sqrt(pt.maximum(pt.as_tensor_variable(n_resp_filled), 1.0)), 1.0, 1000.0) # type: ignore\n",
    "    sigma_meas_base = pm.HalfNormal(\"sigma_meas_base\", 1.0)\n",
    "    sigma_meas = sigma_meas_base / n_eff\n",
    "\n",
    "    # Only impose likelihood where survey actually observed\n",
    "    pm.Normal(\n",
    "        \"survey_obs\",\n",
    "        mu=x_latent[idx_obs],\n",
    "        sigma=sigma_meas[idx_obs],\n",
    "        observed=(x_z[idx_obs]),\n",
    "    )\n",
    "\n",
    "    # --- Outcome model: log productivity (z-scored) ---\n",
    "    # Residual noise\n",
    "    sigma_y = pm.HalfNormal(\"sigma_y\", 0.5)\n",
    "\n",
    "    mu_y = alpha_ou[ou_idx] + time_eff[time_idx] + beta_ou[ou_idx] * x_latent\n",
    "    y_like = pm.Normal(\"y_like\", mu=mu_y, sigma=sigma_y, observed=y_z)\n",
    "\n",
    "    # --- Helpful deterministics for interpretation on original scales ---\n",
    "    pm.Deterministic(\"corr_alpha_beta\", corr_ab[0, 1])\n",
    "    pm.Deterministic(\"beta_global\", mu_beta)\n",
    "\n",
    "     # ---- 4) Sample ----\n",
    "    idata = pm.sample(\n",
    "        draws=1000,\n",
    "        tune=1000,\n",
    "        chains=4,\n",
    "        cores=4,\n",
    "        target_accept=0.9,\n",
    "        random_seed=7,\n",
    "        progressbar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_post_mean = idata.posterior[\"x_latent\"].mean((\"chain\",\"draw\")).values\n",
    "np.corrcoef(x_post_mean[idx_obs], x_z[idx_obs])[0,1]   # expect high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35527752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, arviz as az\n",
    "\n",
    "# Nice labels for OUs\n",
    "ou_labels = pd.Index(pd.Categorical(df[\"ou_code\"]).categories.astype(str), name=\"ou_code\")\n",
    "\n",
    "# Quick tables\n",
    "summ_alpha = az.summary(idata, var_names=[\"alpha_ou\"], hdi_prob=0.9)\n",
    "summ_beta  = az.summary(idata, var_names=[\"beta_ou\"],  hdi_prob=0.9)\n",
    "\n",
    "# Attach OU codes to summaries (indices like 'beta_ou[0]')\n",
    "def add_ou_labels(summ, ou_labels):\n",
    "    lab = []\n",
    "    for idx in summ.index:\n",
    "        i = int(idx.split(\"[\")[1].rstrip(\"]\"))\n",
    "        lab.append(ou_labels[i])\n",
    "    summ = summ.assign(ou_code=lab).set_index(\"ou_code\")\n",
    "    return summ\n",
    "\n",
    "summ_alpha = add_ou_labels(summ_alpha, ou_labels)\n",
    "summ_beta  = add_ou_labels(summ_beta,  ou_labels)\n",
    "\n",
    "print(\"Alpha per OU (posterior mean and 90% HDI):\")\n",
    "display(summ_alpha[[\"mean\",\"hdi_5%\",\"hdi_95%\"]])\n",
    "print(\"\\nBeta per OU (posterior mean and 90% HDI):\")\n",
    "display(summ_beta[[\"mean\",\"hdi_5%\",\"hdi_95%\"]])\n",
    "\n",
    "# Forest plots\n",
    "az.plot_forest(idata, var_names=[\"beta_ou\"], combined=True, hdi_prob=0.9, figsize=(8, 0.35*len(ou_labels)+2))\n",
    "plt.title(\"OU slopes β_g (x* → log-productivity, both z-scored)\")\n",
    "plt.show()\n",
    "\n",
    "az.plot_forest(idata, var_names=[\"alpha_ou\"], combined=True, hdi_prob=0.9, figsize=(8, 0.35*len(ou_labels)+2))\n",
    "plt.title(\"OU intercepts α_g (log-productivity z-score)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, arviz as az\n",
    "# assumes: idata, y_sd, x_sd, df, ou_labels already defined\n",
    "\n",
    "# Pull posterior: dims ~ (chain, draw, beta_ou_dim_0)\n",
    "beta = idata.posterior[\"beta_ou\"]\n",
    "\n",
    "# Map to % change in raw productivity per +1 survey point\n",
    "mult = np.exp((y_sd / x_sd) * beta)\n",
    "pct  = (mult - 1.0) * 100.0  # dims: (chain, draw, ou)\n",
    "\n",
    "# Posterior mean & 90% interval over chain/draw\n",
    "pct_mean = pct.mean(dim=(\"chain\",\"draw\")).values  # shape: (G,)\n",
    "q = pct.quantile([0.05, 0.95], dim=(\"chain\",\"draw\"))          # dims: (quantile, ou)\n",
    "pct_lo = q.sel(quantile=0.05).values\n",
    "pct_hi = q.sel(quantile=0.95).values\n",
    "\n",
    "eff_df = pd.DataFrame({\n",
    "    \"ou_code\": pd.Index(pd.Categorical(df[\"ou_code\"]).categories.astype(str)),\n",
    "    \"pct_mean\": pct_mean, \"pct_lo\": pct_lo, \"pct_hi\": pct_hi\n",
    "}).set_index(\"ou_code\").sort_values(\"pct_mean\")\n",
    "\n",
    "display(eff_df)\n",
    "\n",
    "# Plot interval per OU\n",
    "fig, ax = plt.subplots(figsize=(8, 0.35*len(eff_df)+2))\n",
    "ypos = np.arange(len(eff_df))\n",
    "ax.hlines(y=ypos, xmin=eff_df[\"pct_lo\"], xmax=eff_df[\"pct_hi\"])\n",
    "ax.plot(eff_df[\"pct_mean\"], ypos, \"o\")\n",
    "ax.axvline(0, ls=\"--\", lw=1)\n",
    "ax.set_yticks(ypos, eff_df.index)\n",
    "ax.set_xlabel(\"% change in raw productivity per +1 survey point (90% interval)\")\n",
    "ax.set_title(\"OU-specific effect interpretation\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick tables\n",
    "summ_alpha = az.summary(idata, var_names=[\"alpha_ou\"], hdi_prob=0.9)\n",
    "summ_beta  = az.summary(idata, var_names=[\"beta_ou\"],  hdi_prob=0.9)\n",
    "\n",
    "def add_ou_labels(summ, labels):\n",
    "    labs = []\n",
    "    for idx in summ.index:\n",
    "        i = int(idx.split(\"[\")[1].rstrip(\"]\"))\n",
    "        labs.append(labels[i])\n",
    "    return summ.assign(ou_code=labs).set_index(\"ou_code\")\n",
    "\n",
    "ou_labels = pd.Index(pd.Categorical(df[\"ou_code\"]).categories.astype(str), name=\"ou_code\")\n",
    "display(add_ou_labels(summ_alpha, ou_labels)[[\"mean\",\"hdi_5%\",\"hdi_95%\"]])\n",
    "display(add_ou_labels(summ_beta,  ou_labels)[[\"mean\",\"hdi_5%\",\"hdi_95%\"]])\n",
    "\n",
    "# Forest plots\n",
    "az.plot_forest(idata, var_names=[\"beta_ou\"], combined=True, hdi_prob=0.9,\n",
    "               figsize=(8, 0.35*len(ou_labels)+2))\n",
    "plt.title(\"OU slopes β_g (x* → log-productivity, both z-scored)\"); plt.show()\n",
    "\n",
    "az.plot_forest(idata, var_names=[\"alpha_ou\"], combined=True, hdi_prob=0.9,\n",
    "               figsize=(8, 0.35*len(ou_labels)+2))\n",
    "plt.title(\"OU intercepts α_g (log-productivity z-score)\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6997aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_latent_for_ou(ou_code_str):\n",
    "    labels = pd.Categorical(df[\"ou_code\"]).categories.astype(str)\n",
    "    g = int(np.where(labels == ou_code_str)[0][0])\n",
    "\n",
    "    # rows for this OU, ordered in time\n",
    "    row_idx_all = np.where(pd.Categorical(df[\"ou_code\"]).codes == g)[0]\n",
    "    t = time_idx[row_idx_all]\n",
    "    order = np.argsort(t)\n",
    "    row_idx = row_idx_all[order]\n",
    "    months = pd.to_datetime(unique_months[t[order]])\n",
    "\n",
    "    # posterior summaries for x_latent at those rows\n",
    "    x_da  = idata.posterior[\"x_latent\"]                     # (chain, draw, obs)\n",
    "    x_mu  = x_da.mean((\"chain\",\"draw\")).values[row_idx]\n",
    "    qx    = x_da.quantile([0.05, 0.95], dim=(\"chain\",\"draw\"))\n",
    "    lo    = qx.sel(quantile=0.05).values[row_idx]\n",
    "    hi    = qx.sel(quantile=0.95).values[row_idx]\n",
    "\n",
    "    # observed standardized survey at those rows\n",
    "    obs_mask = has_survey[row_idx]\n",
    "    obs_months = months[obs_mask]\n",
    "    obs_vals   = x_z[row_idx][obs_mask]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.fill_between(months, lo, hi, alpha=0.25, label=\"x* 90% interval\")\n",
    "    ax.plot(months, x_mu, lw=2, label=\"x* posterior mean\")\n",
    "    ax.scatter(obs_months, obs_vals, marker=\"x\", s=60, label=\"observed survey (z)\")\n",
    "    ax.set_title(f\"Latent survey x* over time — OU {ou_code_str}\")\n",
    "    ax.set_ylabel(\"Standardized survey (z)\")\n",
    "    ax.set_xlabel(\"Month\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example\n",
    "plot_latent_for_ou(str(ou_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1459b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plot: OU intercept vs slope post means\n",
    "a_mu = idata.posterior[\"alpha_ou\"].mean((\"chain\",\"draw\")).to_numpy()\n",
    "b_mu = idata.posterior[\"beta_ou\"].mean((\"chain\",\"draw\")).to_numpy()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(a_mu, b_mu)\n",
    "for i, lab in enumerate(ou_labels):\n",
    "    plt.annotate(str(lab), (a_mu[i], b_mu[i]), fontsize=8, xytext=(3,3), textcoords=\"offset points\")\n",
    "plt.axhline(0, lw=1, ls=\"--\"); plt.axvline(0, lw=1, ls=\"--\")\n",
    "plt.xlabel(\"α_g (mean log-productivity z)\"); plt.ylabel(\"β_g (slope)\")\n",
    "plt.title(\"OU intercepts vs slopes (posterior means)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Some single-parameter posteriors\n",
    "az.plot_trace(idata, var_names=[\"beta_global\",\"corr_alpha_beta\",\"sigma_y\",\"sigma_x\",\"sigma_meas_base\"], compact=True, figsize=(10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f69155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "# # Optional: be explicit\n",
    "# os.environ[\"GRAPHVIZ_DOT\"] = \"/opt/homebrew/bin/dot\"\n",
    "# pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738da813",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pm.model_to_graphviz(model)\n",
    "print(g.source[:1000])           # preview DOT text\n",
    "g.save(\"model.dot\")              # write DOT to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5182afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os \n",
    "print (\"dot:\", shutil.which(\"dot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0feee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "print(shutil.which(\"dot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pm.model_to_graphviz(model)\n",
    "g.graph_attr.update(rankdir=\"LR\")  # optional layout\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- 5) Quick checks ----\n",
    "az.summary(idata, var_names=[\n",
    "    \"mu_alpha\", \"mu_beta\", \"sigma_y\", \"sigma_x\", \"sigma_mu_x\",\n",
    "    \"sigma_meas_base\", \"corr_alpha_beta\"\n",
    "], kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39040e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea26943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-bayesian-inference-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
