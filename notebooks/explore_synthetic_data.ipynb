{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14373f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.13\n",
    "# If needed in a fresh env:\n",
    "#   pip install \"pymc>=5.21\" \"arviz>=0.17\" \"numpy>=2\" \"pandas>=2.2\"\n",
    "from pytensor.tensor.variable import TensorVariable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "\n",
    "# ---- 1) Get synthetic data from your helpers ----\n",
    "from bayes_tools.helpers.synthetic_data_helpers import (\n",
    "    make_hierarchical_ou_dataset,\n",
    "    aggregate_to_parent,\n",
    ")\n",
    "\n",
    "# Build OU-level monthly panel\n",
    "df_ou = make_hierarchical_ou_dataset(\n",
    "    n_regions=3,\n",
    "    n_sites_per_region=3,\n",
    "    n_ous_per_site=4,\n",
    "    n_years=3,\n",
    "    wave_months=(6, 12),\n",
    "    wave_missing_prob=0.,\n",
    "    seed=7,\n",
    ")\n",
    "\n",
    "# (Optional) aggregate to parent level (e.g., 'site' or 'region')\n",
    "# df_site = aggregate_to_parent(df_ou, level=\"site\")\n",
    "\n",
    "# We'll model at the OU level:\n",
    "df = df_ou.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c04a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c729090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- 2) Basic feature prep ----\n",
    "# indices\n",
    "df = df.sort_values([\"ou_code\", \"date\"]).reset_index(drop=True)\n",
    "ou_codes = df[\"ou_code\"].astype(\"category\")\n",
    "ou_idx = ou_codes.cat.codes.to_numpy().astype(\"int32\")\n",
    "\n",
    "# time index (month panel)\n",
    "dates = pd.to_datetime(df[\"date\"])\n",
    "unique_months = np.sort(dates.unique())\n",
    "month_to_idx = {m: i for i, m in enumerate(unique_months)}\n",
    "time_idx = np.array([month_to_idx[d] for d in dates], dtype=\"int32\")\n",
    "T = len(unique_months)\n",
    "G = ou_codes.cat.categories.size\n",
    "\n",
    "# outcomes and predictors\n",
    "y_raw = df[\"productivity\"].to_numpy().astype(\"float64\")\n",
    "# log-transform to make noise closer to Gaussian / stabilize variance\n",
    "y = np.log(y_raw).astype(\"float64\")\n",
    "\n",
    "x_obs = df[\"survey_score\"].to_numpy().astype(\"float64\")  # may contain NaN\n",
    "n_resp = df[\"n_respondents\"].to_numpy()                  # NaN where no survey\n",
    "n_resp_filled = np.where(np.isnan(n_resp), 0.0, n_resp).astype(\"float64\")\n",
    "has_survey = ~np.isnan(x_obs)\n",
    "\n",
    "# standardization helpers (kept simple; you can swap for robust scaling)\n",
    "def zscore(a: np.ndarray):\n",
    "    m = np.nanmean(a)\n",
    "    s = np.nanstd(a)\n",
    "    s = s if s > 0 else 1.0\n",
    "    return (a - m) / s, m, s\n",
    "\n",
    "y_z, y_mean, y_sd = zscore(y)      # target\n",
    "x_z = x_obs.copy()\n",
    "if np.isfinite(x_obs[has_survey]).any():\n",
    "    x_z, x_mean, x_sd = zscore(x_obs)\n",
    "else:\n",
    "    # fallback if synthetic happens to miss every survey (unlikely)\n",
    "    x_mean, x_sd = 0.0, 1.0\n",
    "    x_z = (x_obs - x_mean) / x_sd\n",
    "\n",
    "# ---- 3) PyMC model ----\n",
    "with pm.Model() as model:\n",
    "    # --- Global means for OU intercept/slope (on log-productivity scale) ---\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", 0.0, 1.0)\n",
    "    mu_beta  = pm.Normal(\"mu_beta\",  0.0, 0.5)\n",
    "\n",
    "    # --- Correlated OU effects: [alpha, beta] via LKJ-Cholesky for robustness ---\n",
    "    L_ou, corr_ab, sds_ab = pm.LKJCholeskyCov(\n",
    "        \"L_ou\",\n",
    "        n=2,\n",
    "        eta=2.0,\n",
    "        sd_dist=pm.HalfNormal.dist(1.0),\n",
    "        compute_corr=True,\n",
    "        store_in_trace=True,\n",
    "    ) # type: ignore\n",
    "    L_ou: TensorVariable = L_ou\n",
    "    assert isinstance(L_ou, TensorVariable) & isinstance(corr_ab, TensorVariable) & isinstance(sds_ab, TensorVariable)\n",
    "    z = pm.Normal(\"z\", 0.0, 1.0, size=(G, 2))          # Gx2\n",
    "    ab = pt.dot(z, L_ou.T)                              # Gx2\n",
    "    alpha_ou = pm.Deterministic(\"alpha_ou\", mu_alpha + ab[:, 0])\n",
    "    beta_ou  = pm.Deterministic(\"beta_ou\",  mu_beta  + ab[:, 1])\n",
    "\n",
    "    # --- Time fixed effects (centered) for the outcome ---\n",
    "    time_raw = pm.Normal(\"time_raw\", 0.0, 1.0, shape=T)\n",
    "    time_eff = time_raw - pt.mean(time_raw)\n",
    "\n",
    "    # --- Latent survey process x* (z-scored scale) ---\n",
    "    # OU-level mean for x*\n",
    "    mu_x = pm.Normal(\"mu_x\", 0.0, 1.0)\n",
    "    sigma_mu_x = pm.HalfNormal(\"sigma_mu_x\", 1.0)\n",
    "    mu_x_ou = pm.Normal(\"mu_x_ou\", mu_x, sigma_mu_x, shape=G)\n",
    "\n",
    "    # Time effect for x* (optional; helps interpolate sparse waves)\n",
    "    time_x_raw = pm.Normal(\"time_x_raw\", 0.0, 1.0, shape=T)\n",
    "    time_x_eff = time_x_raw - pt.mean(time_x_raw)\n",
    "\n",
    "    # Latent x* per OU-month with residual variance\n",
    "    sigma_x = pm.HalfNormal(\"sigma_x\", 1.0)\n",
    "    x_latent = pm.Normal(\n",
    "        \"x_latent\",\n",
    "        mu_x_ou[ou_idx] + 0.2 * time_x_eff[time_idx],  # small/shrunk time wiggle\n",
    "        sigma_x,\n",
    "        shape=y_z.shape[0],\n",
    "    )\n",
    "\n",
    "    # --- Measurement model where survey is observed ---\n",
    "    # Downweight by sqrt(n_resp): larger n -> lower noise\n",
    "    # Guard against n=0: clamp minimum effective n to 1.\n",
    "    n_eff = pt.clip(pt.sqrt(pt.maximum(pt.as_tensor_variable(n_resp_filled), 1.0)), 1.0, 1000.0) # type: ignore\n",
    "    sigma_meas_base = pm.HalfNormal(\"sigma_meas_base\", 1.0)\n",
    "    sigma_meas = sigma_meas_base / n_eff\n",
    "\n",
    "    # Only impose likelihood where survey actually observed\n",
    "    pm.Normal(\n",
    "        \"survey_obs\",\n",
    "        mu=x_latent[has_survey],\n",
    "        sigma=sigma_meas[has_survey],\n",
    "        observed=(x_z[has_survey]),\n",
    "    )\n",
    "\n",
    "    # --- Outcome model: log productivity (z-scored) ---\n",
    "    # Residual noise\n",
    "    sigma_y = pm.HalfNormal(\"sigma_y\", 0.5)\n",
    "\n",
    "    mu_y = alpha_ou[ou_idx] + time_eff[time_idx] + beta_ou[ou_idx] * x_latent\n",
    "    y_like = pm.Normal(\"y_like\", mu=mu_y, sigma=sigma_y, observed=y_z)\n",
    "\n",
    "    # --- Helpful deterministics for interpretation on original scales ---\n",
    "    pm.Deterministic(\"corr_alpha_beta\", corr_ab[0, 1])\n",
    "    pm.Deterministic(\"beta_global\", mu_beta)\n",
    "\n",
    "    # ---- 4) Sample ----\n",
    "    idata = pm.sample(\n",
    "        draws=1000,\n",
    "        tune=1000,\n",
    "        chains=4,\n",
    "        cores=4,\n",
    "        target_accept=0.9,\n",
    "        random_seed=7,\n",
    "        progressbar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- 5) Quick checks ----\n",
    "az.summary(idata, var_names=[\n",
    "    \"mu_alpha\", \"mu_beta\", \"sigma_y\", \"sigma_x\", \"sigma_mu_x\",\n",
    "    \"sigma_meas_base\", \"corr_alpha_beta\"\n",
    "], kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39040e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea26943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical-bayesian-inference-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
